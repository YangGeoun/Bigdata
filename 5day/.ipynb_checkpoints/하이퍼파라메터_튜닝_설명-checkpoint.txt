"""
<하이퍼파라메터 튜닝>
 - 디폴트 파라메터로 진행한 모델들의 결과값을 "기준"으로...
 - 좀 더 성능을 높을 수 있는 방법을 찾는 과정
 - 하이퍼파라메터는 사람이 개입하여 값들의 범위를 지정하는 방식임
 - 지정된 범위의 하이퍼파라메터를 이용하여, 자동으로 찾아주는 클래스 사용
 
<하이퍼파라메터 튜닝 모델>
 - 모델(클래스) : GridSearchCV()
 - 패키지 : sklearn.model_selection
 
<GridSearchCV()>
 - 각 모델에 대한 하이퍼파라메터의 속성 값들을 스스로 찾아서 훈련까지 수행합니다.
 - "훈련"이라 함은 모델 훈련을 의미합니다.
 - 훈련이 완료된 최적의 모델을 반환 받아서 예측을 수행하게 됩니다.
 - 내부적으로 교차검증(CV, Cross Validation)을 수행하면서 가장 최적의 
   하이퍼파라메터 값들을 찾아내는 방법을 사용합니다.
   
<교차검증(CV, Cross Validation)>
 - 데이터를 자체적으로 독립변수와 종속변수의 여러 그룹으로 쪼개어(Fold) 
 - 교차하면서(그룹의 값들을 섞어 가면서) 검증하는 단계
 - 이때, 검증은 하이퍼파라메터의 범위 값들을 기준으로 각 훈련결과를 비교하면서 검증
 
<시스템 성능 고려해야함>
 - 여러번에 걸친 교차검증이 진행되기에, 시스템 성능에 따라 느리거나 빠르게 결과를 도출
 - 시스템 자원인 CPU Core(코어)는 가급적 전체 사용하게 됩니다.(속도 측면에서)
 
<하이퍼파라메터 튜닝을 하지 않아도 되는 모델>
 - 선형회귀모델은 튜닝 속성이 없습니다.
   (선형, 다항모델은 튜닝 안함, 다중모델의 경우에는 특성공학 직접 적용)
 - 릿시, 라쏘 모델은 강도에 대한 튜닝만 진행되기에 보통 직접 진행합니다.
 - 앙상블 모델들이 자동 튜닝 대상이 됩니다. 
"""