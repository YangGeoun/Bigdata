"""
<훈련 순서>
 1. 모델 생성(딥러닝에서의 모델은 껍데기일 뿐...)
 2. 신경망 계층(Layer) 생성 (1번과 2번은 순서가 바뀔 수 있음)
 3. 모델 환경 설정(손실을 줄이기 위한 방법 설정)
 4. 모델 훈련시키기(fit)
 5. 모델 성능 검증하기(평가)
    --> 성능 검증 결과 : 손실율과 정확도 두가지 값을 반환받아서 확인하게 됩니다.
    *** 딥러닝에서는 정확도보다 손실율을 우선시 합니다.
        --> 스스로 반복 훈련을 하는 이유는 손실이 작을 때까지를 찾기 위함입니다.
        
<성능 개선 방법>
 - 데이터 양을 늘리기
   (딥러닝에서는 데이터의 양이 성능에 크게 좌우됩니다.)
 - 하이퍼파라메터 튜닝
 - 계층(Layer) 추가 또는 삭제
"""





============================================================




"""
<신경망 종류>
 - 인공신경망, 심층신경망

(인공신경망)
 - 계층을 1개 또는 2개를 사용함
 - 1개인 계층 : 입력(Input)과 출력(Output)을 동시에 담당하는 계층
 - 2개인 계층 : 입력계층(Input Layer)과, 출력계층(Output Layer) 2개 사용됨
 
(심층 인공신경망)
 - 계층이 3개 이상 사용함
 - 첫번째 계층 : 입력계층(Input Layer)
 - 마지막 계층 : 출력계층(Output Layer)
 - 중간계층    : 은닉계층(Hidden Layer)
                (히든 계층이라고도 칭함, 여러개 계층 존재 가능)

<계층>
 - 계층은 여러 계층이 존재함
 - 훈련에 참여하는 계층과 훈련에 참여하지 않는 계층으로 구분합니다.
 - 훈련에 참여하는 계층은 주로 Dense()로 생성이 되며,
 - 훈련에 참여하지 않는 계층을 "전처리 계층" 이라고 합니다.
"""





============================================================



### 2. 계층 추가하기
"""
 - Dense() : 딥러닝에서 사용되는 가장 기본적인 계층(클래스), 
           : 훈련에 참여하는 계층(성능에 영향을 미침)
           
 - units : 출력의 갯수를 정의함. 즉, 범주의 갯수를 의미함(범주 10개)
         : units 속성은 출력계층(Output Layer)에 정의됩니다.
         : units이라는 이름은 생략가능
           (단, 입력과 출력계층을 동시에 사용되는 경우에는 생략하면 안됨)
 
 - kernel_initializer : 성능을 높이기 위해 가중치를 초기화하는 방법 지정
   -- 가중치 : 손실을 최소화 하기위해, 모델이 훈련을 반복하는 과정에서
              스스로 성능을 높이기 위해 조정하는 값을 의미함
   (가중치 초기화 방법)
    -- uniform : 균일 분포 방법(훈련 반복 시에 균일하게 가중치를 부여함)
    -- normal  : 가우시안 분포(정규분포) 방법
                (훈련 반복 시에 정규분포를 고려하여 가중치를 부여함)
    -- 초기화 방법은 사람이 정의하지만, 훈련 반복중에 사용되는 가중치 값은
       모델 스스로 사용하게 됨(사람이 관여하지 못함)
       
- activation : "활성화 함수"라고 칭합니다.
  -- 훈련 시 입력된 특성의 갯수를, 어떤 형태의 크기(범주의 갯수)로 변환할지를 
     결정하는 방법을 제시함(이 방법을 함수로 칭합니다.)
  
  -- 주로 출력계층(Output Layer)에 적용됩니다. 
     (은닉계층이 있는 경우에는 은닉계층에도 적용됩니다.)
  -- 활성화 함수는 범주의 갯수(종속변수의 갯수)에 따라서 결정됩니다.
  (활성화 함수 분류 방법)
   * 회귀분석의 경우 : linear 사용 (디폴트 값으로 사용됨)
      - 출력계층에 주로 사용됨
      
   * 분류분석의 경우(이진분류) : sigmoid, relu, tanh, ReakyRelu 중에 사용
                             : (0과 1 둘중 하나 선택)
       - sigmoid : 출력 또는 은닉계층에 주로 사용됨(주로 출력)
       - relu : 출력 또는 은닉계층에 주로 사용됨(주로 은닉)
       - tanh : 은닉계층에 주로 사용됨
       - ReakyRelu : 출력 또는 은닉계층에 주로 사용됨(주로 은닉)ㄴ
       
       
      (이진분류 활설화 함수)
       * sigmoid
         - 보통 출력계층(가장 마지막 계층)에 주로 사용됩니다.
         - 단점, 오른쪽과 왼쪽 끝으로 갈수록 그래프가 누워있기 때문에
                 올바른 출력을 만드는데 어려움이 있음
               , 이는 훈련을 거듭할 수록 누적되기에 성능이 좋아지지 않은 경향을 보임
       * relu
         - sigmoid의 50% 시점으로 분류하지 않고,
           0을 기준으로 0과 1로 분류함(단점을 보완)
         - 기울기가 급함(완만함을 보완하였음)
       * 나머지 : relu를 보완한 향상된 함수
       
   * 분류분석의 경우(다중분류) : softmax (여러 범주 중 하나 선택) 

- input_shape : 입력할 특성(뉴런)의 갯수를 정의함
              : 주로 입력계층(Input Layer)에 사용됨
"""





============================================================



### 3. 모델 환경 설정(손실을 줄이기 위한 방법 설정)
# - 환경 설정을 -> 컴파일(compile) 이라고 칭합니다.
"""
 - compile() : 손실을 줄이기 위한 방법을 설정하는 함수
 - loss : 손실을 줄이기 위해 사용되는 함수 설정(손실함수라고 칭합니다.)
        : 손실함수에는 categorical_crossentropy, sparse_categorical_crossentropy,
          binary_crossentropy가 있습니다.
 (손실함수)
  * categorical_crossentropy
   - 다중분류에 사용됨
   - 단, 종속변수 값의 형태가 원-핫인코딩된 데이터인 경우에 사용됩니다.
   - 원-핫인코딩 종속변수 형태 : [[0, 0, 1], [0, 1, 0], [1, 0, 0] ...]
  
  * sparse_categorical_crossentropy
   - 다중분류에 사용됨(주로 사용됨)
   - 종속변수 형태 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...]
 
  * binary_crossentropy
   - 이진분류에 사용됨
   - 종속변수 형태 : [0, 1, 1, 0, 0, 1...]
   
- metrics : 훈련시 출력할 값 -> 정확도 값 출력(손실률은 기본적으로 출력됨)
"""




